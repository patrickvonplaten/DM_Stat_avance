\section{Study of Price as a Function of Mileage} % (fold)
\label{sec:price_km}

\subsection{Simple Regression} % (fold)
\label{sub:simple_regression}

A simple regression of \textit{price} on milage represented by the variable \textit{km} shows quite different results. As in Section \ref{sec:price_abs}, we begin by performing a simple regression using the equation

\begin{equation}\label{eq:price_km}
	price = \beta_0 + \beta_1 \times km + \epsilon
\end{equation}

\noindent
where $\beta_0$ is the intercept, $\beta_1$ is the slope and $\epsilon$ is 
the residual variable. Applying this to our data results in $\beta_0$ and 
$\beta_1$ values of 5.559202 and -0.016051. Using the same analysis and 
reasoning as in \ref{sec:price_abs}, $km$ is obviously a better parameter to 
describe the price of a car. The coefficent of detirmination $R^2$ is much 
higher (0.3317) and the p-value is much lower ($<2e^{16}$), suggesting that 
\textit{km} should be in model explaining the price.

% subsection simple_regression (end)
\subsection{Inference from Simple Model} % (fold)
\label{sub:inference_from_simple_model}

We will now using the simple model from the previous section create confidence intervals of prices for cars with difference milages. This was implemented in \textit{R} using the \textit{predict} function. For a cars with a milages of 50 000 km and 135 000 km a confindence intervals at the defult significance level 95\% are shown in Table \ref{tab:confint_km}.

\begin{table}[H]
\centering
\begin{tabular}{||c |c c c||} 
 \hline
 Mileage & fit & lower & upper \\ [0.5ex]
 \hline
 50 000 km & 4.756639 & 4.426392 & 5.086886 \\ 
 136 000 km & 3.392284 & 3.238505 & 3.546063 \\
 \hline
\end{tabular}
\caption{Confindence intervals at 95\% confidence level for cars with milages of 50 000 km and 135 000 km}
\label{tab:confint_km}
\end{table}

\noindent
We see that the confidence intervall for a car that has 135 000 km milage is much smaller than the other at the same sig. level. This implies that the variance of the price for cars having 135 000 km is lower that can be justified by the fact that the price of cars already having a high usage (in terms of km) are naturally lower and don't vary as much. Whereas for cars having lower usage (50 000 km) the price can vary much more since other factors play a more important role in determining its price (car type, car performance.) Also, it should be noted that 135 000 km is the mean of all of the data. Since the sample follows a t-distribution, it is normal that there is more data around 135 000 km (the distribution is denser). Therefore the 95\% confidence intervall has a shorter lenght than the one at 50 000 km.
% subsection inference_from_simple_model (end)

\subsection{Determination of Mystery Variable \textit{kop1}} % (fold)
\label{sub:det_myst_var}

The data set given includes the variable \textit{kop1} given wit hout explaination of what it charectarizes. In fact, it reduces to the variable \textit{km} as it is a centered and reduced version of it.

\begin{equation}\label{eq:1}
	kop1 = \frac{km - mean(km)}{SD(km)}
\end{equation}

\noindent
In fact, simple regression models based on \textit{kop1} and \textit{km} result in the exact same model. It can be shown that the models are logically the same since $R^2$ and other important functions are equal. Algerbrically this can be show through the following reasoning. The regression model is given by the following equation:

\begin{equation}\label{eq:price_kop1}
	price = \gamma_0 + \gamma_1 \times kop1 + e
\end{equation}

\noindent
Where $\gamma_i$ are the coefficents and $e$ is the residual. Using relationship \ref{eq:1} the regression model reduces to

\begin{equation}
	 price = \gamma_0 + \gamma_1 \times (km + mean(km))+ e = (\gamma_0 + \gamma_1 \times mean(km)) + \gamma_1 \times km + e
\end{equation}

\noindent
Given that $mean(km)$ is a constant, we note that this is this equivant with the regression model \ref{eq:price_km} as $\beta_0 = (\gamma_0 + \gamma_1 \times mean(km))$, $\beta_1 = \gamma_1$ and the residuals $\epsilon = e$.
	
% need a good explanation for this one!!!
% --> explain mathematically why T VALUE, Pr(>|t|) and F-statistic and R^2
% are the same. 
It is obvious that centering and reducing shouldn't change anything. The regression looks at how changes in the X value affect the Y vaule

% En effet, th??oriquement, on doit trouver un coefficient directeur ??gale ?? l?????cart type de la variable km fois le coefficient directeur initialement trouv?? et similairement
% l???intercept doit ??tre ??gale ?? l???ancien intercept plus l???ancien coefficient directeur fois la moyenne de km.
% subsection determination_of_mystery_variable (end)

% section det_myst_var (end)